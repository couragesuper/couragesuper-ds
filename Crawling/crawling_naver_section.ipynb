{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "sys.path.append('/root/Python/Common/NLP/Crawler')\n",
    "\n",
    "import mod_craw as craw\n",
    "from mod_craw_logger import Crawler_Logger as LOGGER\n",
    "from mod_craw_filewriter import crawler_filewriter as FT\n",
    "from mod_crawler_base import crawler_base as crawler_main\n",
    "from time import sleep\n",
    "from selenium import webdriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "listSectionNm    = ['종합', '정치', '경제', '사회', '생활/문화', '세계', 'IT/과학', '포토', 'TV']\n",
    "listSectionID    = ['100', '101', '102', '103', '104', '105', '106', '003', '115']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class crawler_joins_keyword (crawler_main):\n",
    "    def __init__( self , isLinux, isHidden, keyword_en, keyword ) :\n",
    "        self.keyword = keyword\n",
    "        super().__init__(isLinux,isHidden, keyword_en)\n",
    "    def run(self):        \n",
    "        baseUrl = \"https://news.joins.com/find/list?IsDuplicate=True&key=EditorialColumn&Keyword=%s&SourceGroupType=Joongang\" % (self.keyword)\n",
    "        super().run( baseUrl )\n",
    "    def naviSites(self):\n",
    "        baseUrl = \"https://news.joins.com/find/list?page=%d&IsDuplicate=True&key=EditorialColumn&Keyword=%s&SourceGroupType=Joongang\" % (1, self.keyword)\n",
    "        self.openPage(baseUrl)\n",
    "        self.navigate(baseUrl)\n",
    "        sleep(1)\n",
    "    def getMaxPages(self):\n",
    "        baseUrl = \"https://news.joins.com/find/list?page=1&IsDuplicate=True&key=EditorialColumn&Keyword=%s&SourceGroupType=Joongang\" % (self.keyword)\n",
    "        css_name = \"btn_next\"\n",
    "        self.openPage(baseUrl)\n",
    "        while (True):\n",
    "            elem = self.webDrv.find_element_by_class_name(css_name)\n",
    "            pos = elem.text.find(\"없음\")\n",
    "            if (pos == -1):\n",
    "                print(\"다음페이지 있음\")\n",
    "                elem.click()\n",
    "            else:\n",
    "                print(\"다음페이지 없음\")\n",
    "                elems = self.webDrv.find_elements_by_class_name('link_page')\n",
    "                listPages = []\n",
    "                for eobj in elems:\n",
    "                    listPages.append(int(eobj.text))\n",
    "                listPages = sorted(listPages, reverse=True)\n",
    "                return listPages[0]\n",
    "            sleep(0.5)\n",
    "    def navigate(self , link):\n",
    "        max_page = self.getMaxPages( )\n",
    "        for i in range(1, max_page + 1):\n",
    "            self.navigatePage( i, False )\n",
    "            sleep(2)\n",
    "    def navigatePage( self,page, isShowContent ):\n",
    "        now = time.localtime()\n",
    "        print(page)\n",
    "        baseUrl = \"https://news.joins.com/find/list?page=%d&IsDuplicate=True&key=EditorialColumn&Keyword=%s&SourceGroupType=Joongang\" % (page, self.keyword )\n",
    "        self.openPage( baseUrl )\n",
    "        listLink = []\n",
    "        listElem = self.webDrv.find_elements_by_class_name('headline')\n",
    "        if (self.isTxt == False ) :\n",
    "            print(\"text file isnt configured.\")\n",
    "            return\n",
    "        for i, elem in enumerate(listElem):\n",
    "            listLink.append(elem.find_element_by_tag_name('a').get_attribute('href'))\n",
    "        for i, elem in enumerate(listLink):\n",
    "            url = listLink[i]\n",
    "            if( self.logger.getHistory(url) == False ) :\n",
    "                try:\n",
    "                    start_time = time.time()\n",
    "                    self.openPage(url)\n",
    "                    self.crawContents(True)\n",
    "                    self.logger.updateHistory(url, \"ok\")\n",
    "                except:\n",
    "                    self.logger.updateHistory(url, \"fail\")\n",
    "            sleep(1)\n",
    "        self.logger.close()\n",
    "    def crawContents(self,isShowContent):\n",
    "        #article_title\n",
    "        elem = self.webDrv.find_element_by_id('article_title')\n",
    "        txt_head = elem.text\n",
    "        self.txt.write(txt_head)\n",
    "        #byline\n",
    "        elem = self.webDrv.find_element_by_class_name('byline')\n",
    "        txt_date_input = elem.text.split()[2]\n",
    "        self.txt.write(txt_date_input)\n",
    "        #profile\n",
    "        elem = self.webDrv.find_element_by_class_name('profile')\n",
    "        txt_profile = elem.text\n",
    "        self.txt.write(txt_profile)\n",
    "        # tags , |로 구분\n",
    "        elem = self.webDrv.find_element_by_class_name('tag_list')\n",
    "        listTags = elem.text.split(\"#\")[1:]\n",
    "        szTags = \"\"\n",
    "        for tags in listTags:\n",
    "            szTags += tags.replace(\"\\n\", \"\")\n",
    "            szTags += \"|\"\n",
    "        if (isShowContent): print(szTags)\n",
    "        self.txt.write(szTags)\n",
    "        #article_body\n",
    "        elem = self.webDrv.find_element_by_class_name('article_body')\n",
    "        txt_org = elem.text\n",
    "        txt_proc = txt_org.replace(\"\\n\", \"  \")\n",
    "        if (isShowContent): print(txt_proc)\n",
    "        self.txt.writeLast(txt_proc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Crawler_Logger] create new file\n",
      "[Crawler_Logger] history node: None\n"
     ]
    }
   ],
   "source": [
    "MOD = crawler_joins_keyword(True, True, \"Joins_Sasul\", \"사설\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = craw.InitWebDriver(True,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://news.naver.com\"\n",
    "craw.OpenWebPage( wd, url , 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "listSectionNm = ['종합', '정치', '경제', '사회', '생활/문화', '세계', 'IT/과학', '포토', 'TV']\n",
    "listSectionID = ['100','101','102','103','104','105','106','003','115']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
